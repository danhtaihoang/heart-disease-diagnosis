{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Reflection for Heart Disease Diagnosis\n",
    "In this work, we apply our method, Expectation Reflection (ER), to predict diabetes from Pima Indians Diabetes dataset. We compare the performance of ER with other existing methods such as Logistic Regression, Naive Bayes, Dicision Tree, Random Forest, k-nearest neighbors, and Support Vector Machines (SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from inference import fit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "5   57    1   0       140   192    0        1      148      0      0.4      1   \n",
       "6   56    0   1       140   294    0        0      153      0      1.3      1   \n",
       "7   44    1   1       120   263    0        1      173      0      0.0      2   \n",
       "8   52    1   2       172   199    1        1      162      0      0.5      2   \n",
       "9   57    1   2       150   168    0        1      174      0      1.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  \n",
       "5   0     1       1  \n",
       "6   0     2       1  \n",
       "7   0     3       1  \n",
       "8   0     3       1  \n",
       "9   0     2       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('heartdisease_data.csv',sep= ',')\n",
    "df[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains 13 features:<br/>\n",
    "0) age: Age (years) --> discrete <br/>\n",
    "1) sex: Sex (1: male, 0: female) --> categorical <br/>\n",
    "2) cp: Chest pain type (1: typical angina, 2: atypical angina, 3: non-anginal pain, 4: asymptomatic) --> categorical <br/>\n",
    "3) trestbps: Resting blood pressure (mm Hg on admission to the hospital) --> continuous <br/>\n",
    "4) chol: Cholesterol measurement (mg/dl) --> continuous <br/>\n",
    "5) fbs: Fasting blood sugar (0: <120 mg/dl, 1: > 120 mg/dl) --> categorical <br/>\n",
    "6) restecg: Resting electrocardiographic measurement (0: normal, 1: having ST-T wave abnormality, 2: showing probable or definite left ventricular hypertrophy by Estes' criteria) --> categorical <br/>\n",
    "7) thalach: Maximum heart rate achieved --> continuous<br/>\n",
    "8) exang: Exercise induced angina (1: yes; 0: no) --> categorical <br/>\n",
    "9) oldpeak: ST depression induced by exercise relative to rest ('ST' relates to positions on the ECG plot) --> continuous<br/>\n",
    "10) slope: The slope of the peak exercise ST segment (1: upsloping, 2: flat, 3: downsloping) --> categorical<br/>\n",
    "11) ca: The number of major vessels (0-4) --> categorical <br/>\n",
    "12) thal: Thalassemia (a type of blood disorder)  (1: normal; 2: fixed defect; 3: reversable defect) --> categorical <br/>\n",
    "\n",
    "and 1 target: Heart disease (0: no, 1: yes) <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 13)\n"
     ]
    }
   ],
   "source": [
    "# select features and target:\n",
    "df = np.array(df).astype(float)\n",
    "\n",
    "# features:\n",
    "X = df[:,:-1]\n",
    "l,n = X.shape\n",
    "print(l,n)\n",
    "\n",
    "# target:\n",
    "y = df[:,-1]\n",
    "# convert 1,0 to 1,-1:\n",
    "y = 2*y - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert categorical variables to one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False,categories='auto')\n",
    "\n",
    "# sex = X[:,1] = 0,1 --> 2\n",
    "x1 = onehot_encoder.fit_transform(X[:,1].reshape(-1,1))\n",
    "\n",
    "# cp = X[:,2] = 1,2,3,4 --> 4\n",
    "x2 = onehot_encoder.fit_transform(X[:,2].reshape(-1,1))\n",
    "\n",
    "# fbs = X[:,5] = 0,1 --> 2\n",
    "x5 = onehot_encoder.fit_transform(X[:,5].reshape(-1,1)) \n",
    "\n",
    "# restecg = X[:,6] = 0,1,2 --> 3\n",
    "x6 = onehot_encoder.fit_transform(X[:,6].reshape(-1,1))\n",
    "\n",
    "#exang: = X[:,8] = 0,1 --> 2\n",
    "x8 = onehot_encoder.fit_transform(X[:,8].reshape(-1,1))\n",
    "\n",
    "# X[:,10] = 0,1,2 --> 3\n",
    "x10 = onehot_encoder.fit_transform(X[:,10].reshape(-1,1))\n",
    "\n",
    "# X[:,11] = 0,1,2,3,4 --> 5\n",
    "x11 = onehot_encoder.fit_transform(X[:,11].reshape(-1,1)) \n",
    "\n",
    "# X[:,12] = 0,1,2,3 --> 4\n",
    "x12= onehot_encoder.fit_transform(X[:,12].reshape(-1,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = np.hstack([X[:,0][:,np.newaxis],x1])\n",
    "Xnew = np.hstack([Xnew,x2])\n",
    "Xnew = np.hstack([Xnew,X[:,3:5]])\n",
    "Xnew = np.hstack([Xnew,x5])\n",
    "Xnew = np.hstack([Xnew,x6])\n",
    "Xnew = np.hstack([Xnew,X[:,7][:,np.newaxis]])\n",
    "Xnew = np.hstack([Xnew,x8])\n",
    "Xnew = np.hstack([Xnew,X[:,9][:,np.newaxis]])\n",
    "Xnew = np.hstack([Xnew,x10])\n",
    "Xnew = np.hstack([Xnew,x11])\n",
    "Xnew = np.hstack([Xnew,x12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Xnew\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction with Expectation Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation_reflection_inference(X,y,kf=5,regu=0.005):    \n",
    "    #x_train,x_test,y_train,y_test = train_test_split(X1,y,test_size=0.3,random_state = 100)    \n",
    "    kfold = KFold(n_splits=kf,shuffle=False,random_state=1)\n",
    "    accuracy = np.zeros(kf)\n",
    "    \n",
    "    for i,(train_index,test_index) in enumerate(kfold.split(y)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # predict with ER\n",
    "        h0,w = fit(X_train,y_train,niter_max=100,regu=0.005)\n",
    "        h_pred = h0 + X_test.dot(w)\n",
    "        y_pred = np.sign(h_pred)\n",
    "        accuracy[i] = accuracy_score(y_test,y_pred)\n",
    "        #print(accuracy[i])\n",
    "    return accuracy.mean(),accuracy.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ER:', 0.8186885245901638, 0.028293982295579306, 0.0)\n",
      "('ER:', 0.8186885245901638, 0.028293982295579306, 0.001)\n",
      "('ER:', 0.8186885245901638, 0.028293982295579306, 0.002)\n",
      "('ER:', 0.8186885245901638, 0.028293982295579306, 0.003)\n",
      "('ER:', 0.8186885245901638, 0.028293982295579306, 0.004)\n",
      "('ER:', 0.8186885245901638, 0.028293982295579306, 0.005)\n",
      "('ER:', 0.8186885245901638, 0.028293982295579306, 0.01)\n",
      "('ER:', 0.8186885245901638, 0.028293982295579306, 0.02)\n",
      "('ER:', 0.8186885245901638, 0.028293982295579306, 0.1)\n",
      "('ER:', 0.8186885245901638, 0.028293982295579306, 0.2)\n",
      "('ER:', 0.8186885245901638, 0.028293982295579306, 0.5)\n"
     ]
    }
   ],
   "source": [
    "regu_list = [0.0,0.001,0.002,0.003,0.004,0.005,0.01,0.02,0.1,0.2,0.5]\n",
    "for regu in regu_list:\n",
    "    accuracy_mean,accuracy_std = expectation_reflection_inference(X,y,kf,regu)\n",
    "    print('ER:',accuracy_mean,accuracy_std,regu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with other existing machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def inference(X,y,kf=5,method='naive_bayes'):     \n",
    "    kfold = KFold(n_splits=kf,shuffle=False,random_state=1)            \n",
    "    accuracy = np.zeros(kf)\n",
    "            \n",
    "    if method == 'logistic_regression':\n",
    "        model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "    if method == 'naive_bayes': \n",
    "        model = GaussianNB()\n",
    "        \n",
    "    if method == 'random_forest':\n",
    "        model = RandomForestClassifier(criterion = \"gini\", random_state = 1,\n",
    "                               max_depth=3, min_samples_leaf=5,n_estimators=100)        \n",
    "    if method == 'decision_tree':\n",
    "        model = DecisionTreeClassifier()\n",
    "        \n",
    "    if method == 'knn':    \n",
    "        model = KNeighborsClassifier()\n",
    "        \n",
    "    if method == 'svm':    \n",
    "        model = SVC(gamma='scale')     \n",
    "        \n",
    "    for i,(train_index,test_index) in enumerate(kfold.split(y)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # fit and predict\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        accuracy[i] = accuracy_score(y_test,y_pred)\n",
    "        #print(accuracy[i])\n",
    "    return accuracy.mean(),accuracy.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('         naive_bayes :', 0.766120218579235, 0.07444460266062984)\n",
      "(' logistic_regression :', 0.8155191256830602, 0.042188623591959885)\n",
      "('       decision_tree :', 0.7429508196721312, 0.060649189820353)\n",
      "('       random_forest :', 0.8156830601092896, 0.06756352745946796)\n",
      "('                 knn :', 0.8252459016393443, 0.04073498358163241)\n",
      "('                 svm :', 0.8055191256830602, 0.030572976935354525)\n"
     ]
    }
   ],
   "source": [
    "other_methods=['naive_bayes','logistic_regression','decision_tree','random_forest','knn','svm']\n",
    "\n",
    "for i,method in enumerate(other_methods):\n",
    "    accuracy_mean,accuracy_std = inference(X,y,kf,method)\n",
    "    print('% 20s :'%method,accuracy_mean,accuracy_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small sample sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ER:', 0.82, 0.03999999999999999, 0.0)\n",
      "('ER:', 0.82, 0.03999999999999999, 0.001)\n",
      "('ER:', 0.82, 0.03999999999999999, 0.002)\n",
      "('ER:', 0.82, 0.03999999999999999, 0.003)\n",
      "('ER:', 0.82, 0.03999999999999999, 0.004)\n",
      "('ER:', 0.82, 0.03999999999999999, 0.005)\n",
      "('ER:', 0.82, 0.03999999999999999, 0.01)\n",
      "('ER:', 0.82, 0.03999999999999999, 0.02)\n",
      "('ER:', 0.82, 0.03999999999999999, 0.1)\n",
      "('ER:', 0.82, 0.03999999999999999, 0.2)\n",
      "('ER:', 0.82, 0.03999999999999999, 0.5)\n"
     ]
    }
   ],
   "source": [
    "regu_list = [0.0,0.001,0.002,0.003,0.004,0.005,0.01,0.02,0.1,0.2,0.5]\n",
    "for regu in regu_list:\n",
    "    accuracy_mean,accuracy_std = expectation_reflection_inference(X[:100,:],y[:100],kf,regu)\n",
    "    print('ER:',accuracy_mean,accuracy_std,regu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('         naive_bayes :', 0.78, 0.05099019513592786)\n",
      "(' logistic_regression :', 0.8, 0.04472135954999579)\n",
      "('       decision_tree :', 0.74, 0.07999999999999999)\n",
      "('       random_forest :', 0.82, 0.03999999999999999)\n",
      "('                 knn :', 0.86, 0.03741657386773942)\n",
      "('                 svm :', 0.8200000000000001, 0.024494897427831747)\n"
     ]
    }
   ],
   "source": [
    "other_methods=['naive_bayes','logistic_regression','decision_tree','random_forest','knn','svm']\n",
    "\n",
    "for i,method in enumerate(other_methods):\n",
    "    accuracy_mean,accuracy_std = inference(X[:100,:],y[:100],kf,method)\n",
    "    print('% 20s :'%method,accuracy_mean,accuracy_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ER:', 0.7200000000000001, 0.17204650534085256, 0.0)\n",
      "('ER:', 0.74, 0.17435595774162696, 0.001)\n",
      "('ER:', 0.7200000000000001, 0.17204650534085256, 0.002)\n",
      "('ER:', 0.7200000000000001, 0.17204650534085256, 0.003)\n",
      "('ER:', 0.74, 0.17435595774162696, 0.004)\n",
      "('ER:', 0.74, 0.17435595774162696, 0.005)\n",
      "('ER:', 0.7200000000000001, 0.17204650534085256, 0.01)\n",
      "('ER:', 0.74, 0.17435595774162696, 0.02)\n",
      "('ER:', 0.7200000000000001, 0.17204650534085256, 0.1)\n",
      "('ER:', 0.7200000000000001, 0.17204650534085256, 0.2)\n",
      "('ER:', 0.74, 0.17435595774162696, 0.5)\n"
     ]
    }
   ],
   "source": [
    "for regu in regu_list:\n",
    "    accuracy_mean,accuracy_std = expectation_reflection_inference(X[:50,:],y[:50],kf,regu)\n",
    "    print('ER:',accuracy_mean,accuracy_std,regu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('         naive_bayes :', 0.74, 0.233238075793812)\n",
      "(' logistic_regression :', 0.7000000000000001, 0.14142135623730953)\n",
      "('       decision_tree :', 0.6, 0.20976176963403032)\n",
      "('       random_forest :', 0.76, 0.1356465996625054)\n",
      "('                 knn :', 0.76, 0.10198039027185572)\n",
      "('                 svm :', 0.7200000000000001, 0.16)\n"
     ]
    }
   ],
   "source": [
    "for i,method in enumerate(other_methods):\n",
    "    accuracy_mean,accuracy_std = inference(X[:50,:],y[:50],kf,method)\n",
    "    print('% 20s :'%method,accuracy_mean,accuracy_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
